{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-09-06T18:07:41.479435Z",
          "iopub.execute_input": "2023-09-06T18:07:41.480300Z",
          "iopub.status.idle": "2023-09-06T18:07:41.899572Z",
          "shell.execute_reply.started": "2023-09-06T18:07:41.480256Z",
          "shell.execute_reply": "2023-09-06T18:07:41.897809Z"
        },
        "trusted": true,
        "id": "bvumukOSllT0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "9yIiCWZallT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%config Completer.use_jedi = False\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install text_hammer\n",
        "import text_hammer as th\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from wordcloud import STOPWORDS\n",
        "from collections import defaultdict\n",
        "#%%time\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "from transformers import AutoTokenizer,TFBertModel\n",
        "\n",
        "max_len = 36\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy,BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy,BinaryAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:09:11.785293Z",
          "iopub.execute_input": "2023-09-06T18:09:11.785918Z",
          "iopub.status.idle": "2023-09-06T18:09:41.475861Z",
          "shell.execute_reply.started": "2023-09-06T18:09:11.785881Z",
          "shell.execute_reply": "2023-09-06T18:09:41.474540Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cHfEFQMllT2",
        "outputId": "1f2c2446-f3b4-4f02-edf8-695c8003c91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: text_hammer in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.1 in /usr/local/lib/python3.10/dist-packages (from text_hammer) (4.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from text_hammer) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from text_hammer) (1.25.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from text_hammer) (3.7.4)\n",
            "Requirement already satisfied: TextBlob in /usr/local/lib/python3.10/dist-packages (from text_hammer) (0.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.9.1->text_hammer) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text_hammer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text_hammer) (2023.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.3.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from TextBlob->text_hammer) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->TextBlob->text_hammer) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->TextBlob->text_hammer) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->TextBlob->text_hammer) (2023.12.25)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->text_hammer) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->text_hammer) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->text_hammer) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->text_hammer) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->text_hammer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->text_hammer) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->text_hammer) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->text_hammer) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ALvuL2outRcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading The Data"
      ],
      "metadata": {
        "id": "lmOfK-B_llT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "new_directory = \"/content/sample_data\"\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir(new_directory)\n",
        "current_directory = os.getcwd()\n",
        "for item in os.listdir(current_directory):\n",
        "    if os.path.isdir(os.path.join(current_directory, item)):\n",
        "        print(item)\n",
        "\n",
        "print(current_directory)\n",
        "\n",
        "train_data = pd.read_csv('train.csv',usecols=['id','text','target'])\n",
        "test_data = pd.read_csv('test.csv',usecols=['id','text'])\n",
        "sample_data = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:09:41.477600Z",
          "iopub.execute_input": "2023-09-06T18:09:41.478462Z",
          "iopub.status.idle": "2023-09-06T18:09:41.560102Z",
          "shell.execute_reply.started": "2023-09-06T18:09:41.478422Z",
          "shell.execute_reply": "2023-09-06T18:09:41.559151Z"
        },
        "trusted": true,
        "id": "qomCcsbDllT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:10:56.905335Z",
          "iopub.execute_input": "2023-09-06T18:10:56.905749Z",
          "iopub.status.idle": "2023-09-06T18:10:56.916250Z",
          "shell.execute_reply.started": "2023-09-06T18:10:56.905716Z",
          "shell.execute_reply": "2023-09-06T18:10:56.915109Z"
        },
        "trusted": true,
        "id": "afD-vV48llT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.tail()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:11:10.586733Z",
          "iopub.execute_input": "2023-09-06T18:11:10.587129Z",
          "iopub.status.idle": "2023-09-06T18:11:10.597845Z",
          "shell.execute_reply.started": "2023-09-06T18:11:10.587101Z",
          "shell.execute_reply": "2023-09-06T18:11:10.596436Z"
        },
        "trusted": true,
        "id": "LdQmkbEBllT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:11:19.619555Z",
          "iopub.execute_input": "2023-09-06T18:11:19.620012Z",
          "iopub.status.idle": "2023-09-06T18:11:19.631890Z",
          "shell.execute_reply.started": "2023-09-06T18:11:19.619975Z",
          "shell.execute_reply": "2023-09-06T18:11:19.630683Z"
        },
        "trusted": true,
        "id": "z509p4SjllT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.tail()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:11:29.741391Z",
          "iopub.execute_input": "2023-09-06T18:11:29.742574Z",
          "iopub.status.idle": "2023-09-06T18:11:29.753961Z",
          "shell.execute_reply.started": "2023-09-06T18:11:29.742521Z",
          "shell.execute_reply": "2023-09-06T18:11:29.752664Z"
        },
        "trusted": true,
        "id": "YHw-EjHNllT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:11:46.474894Z",
          "iopub.execute_input": "2023-09-06T18:11:46.475909Z",
          "iopub.status.idle": "2023-09-06T18:11:46.483055Z",
          "shell.execute_reply.started": "2023-09-06T18:11:46.475864Z",
          "shell.execute_reply": "2023-09-06T18:11:46.481668Z"
        },
        "trusted": true,
        "id": "4_q6WKp4llT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data_frame, column_name):\n",
        "    column = column_name\n",
        "    data_frame[column] = data_frame[column].progress_apply(lambda x: str(x).lower())\n",
        "    data_frame[column] = data_frame[column].progress_apply(lambda x: th.remove_emails(x))\n",
        "    data_frame[column] = data_frame[column].progress_apply(lambda x: th.remove_html_tags(x))\n",
        "    data_frame[column] = data_frame[column].progress_apply(lambda x: th.remove_special_chars(x))\n",
        "    data_frame[column] = data_frame[column].progress_apply(lambda x: th.remove_accented_chars(x))\n",
        "    return data_frame\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:12:02.702526Z",
          "iopub.execute_input": "2023-09-06T18:12:02.702927Z",
          "iopub.status.idle": "2023-09-06T18:12:02.711298Z",
          "shell.execute_reply.started": "2023-09-06T18:12:02.702897Z",
          "shell.execute_reply": "2023-09-06T18:12:02.709970Z"
        },
        "trusted": true,
        "id": "epf9mPU7llT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cleaned_data = preprocess(train_data,'text')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:12:14.355009Z",
          "iopub.execute_input": "2023-09-06T18:12:14.355450Z",
          "iopub.status.idle": "2023-09-06T18:12:16.483192Z",
          "shell.execute_reply.started": "2023-09-06T18:12:14.355420Z",
          "shell.execute_reply": "2023-09-06T18:12:16.481817Z"
        },
        "trusted": true,
        "id": "dwF_oUvzllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cleaned_data[train_cleaned_data.target == 0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:12:29.453052Z",
          "iopub.execute_input": "2023-09-06T18:12:29.453484Z",
          "iopub.status.idle": "2023-09-06T18:12:29.472433Z",
          "shell.execute_reply.started": "2023-09-06T18:12:29.453451Z",
          "shell.execute_reply": "2023-09-06T18:12:29.471306Z"
        },
        "trusted": true,
        "id": "vEe5ytGollT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_cleaned_data.copy()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:12:51.657100Z",
          "iopub.execute_input": "2023-09-06T18:12:51.657533Z",
          "iopub.status.idle": "2023-09-06T18:12:51.665068Z",
          "shell.execute_reply.started": "2023-09-06T18:12:51.657500Z",
          "shell.execute_reply": "2023-09-06T18:12:51.663270Z"
        },
        "trusted": true,
        "id": "VDMoIHRSllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(10)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:13:00.458584Z",
          "iopub.execute_input": "2023-09-06T18:13:00.459009Z",
          "iopub.status.idle": "2023-09-06T18:13:00.469381Z",
          "shell.execute_reply.started": "2023-09-06T18:13:00.458976Z",
          "shell.execute_reply": "2023-09-06T18:13:00.468376Z"
        },
        "trusted": true,
        "id": "t6rocLhIllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Target 1 indicates any accident or disaster\n",
        "* Target 0 indicates a no attetntion\n"
      ],
      "metadata": {
        "id": "gTB623-WllT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud:"
      ],
      "metadata": {
        "id": "DkXbSRUNllT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JNxEmykUllT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "train_data['text'] = train_data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:15:32.086424Z",
          "iopub.execute_input": "2023-09-06T18:15:32.086889Z",
          "iopub.status.idle": "2023-09-06T18:15:32.127113Z",
          "shell.execute_reply.started": "2023-09-06T18:15:32.086858Z",
          "shell.execute_reply": "2023-09-06T18:15:32.126135Z"
        },
        "trusted": true,
        "id": "PnSm50rmllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Disaster Tweets wordcloud\n",
        "disaster_tweets = train_data[train_data.target == 1]\n",
        "\n",
        "# Concatenate disaster tweets into a single string\n",
        "disaster_text = []\n",
        "for tweet in disaster_tweets.text:\n",
        "    disaster_text.append(tweet)\n",
        "disaster_text = pd.Series(disaster_text).str.cat(sep=' ')\n",
        "\n",
        "# Generate word cloud\n",
        "cloud_disaster = WordCloud(width=1600, height=800, max_font_size=200, background_color='white').generate(disaster_text)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.imshow(cloud_disaster, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:16:22.698269Z",
          "iopub.execute_input": "2023-09-06T18:16:22.698705Z",
          "iopub.status.idle": "2023-09-06T18:16:25.877135Z",
          "shell.execute_reply.started": "2023-09-06T18:16:22.698675Z",
          "shell.execute_reply": "2023-09-06T18:16:25.876065Z"
        },
        "trusted": true,
        "id": "_54ux1JWllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formal_tweets = train_data[train_data.target == 0]\n",
        "formal_string = []\n",
        "for t in formal_tweets.text:\n",
        "    formal_string.append(t)\n",
        "formal_string = pd.Series(formal_string).str.cat(sep=' ')\n",
        "wordcloud = WordCloud(width=1600, height=800,max_font_size=200, background_color='white').generate(formal_string)\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:17:48.325201Z",
          "iopub.execute_input": "2023-09-06T18:17:48.325614Z",
          "iopub.status.idle": "2023-09-06T18:17:51.582850Z",
          "shell.execute_reply.started": "2023-09-06T18:17:48.325586Z",
          "shell.execute_reply": "2023-09-06T18:17:51.577615Z"
        },
        "trusted": true,
        "id": "CfIjYz5CllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing class distribution\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(y='target',data = train_data,palette=\"Paired\")\n",
        "plt.ylabel(\"Tweet problem\")\n",
        "plt.xlabel(\"# of tweets\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:18:03.878430Z",
          "iopub.execute_input": "2023-09-06T18:18:03.878864Z",
          "iopub.status.idle": "2023-09-06T18:18:04.077550Z",
          "shell.execute_reply.started": "2023-09-06T18:18:03.878834Z",
          "shell.execute_reply": "2023-09-06T18:18:04.076595Z"
        },
        "trusted": true,
        "id": "m7WxS-zQllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing tweet length by characaters\n",
        "plt.figure(figsize=(10,5))\n",
        "train_sent = train_data['text'].str.len()\n",
        "sns.boxplot(x=\"target\",y=train_sent,data=train_data,palette=\"Set2\")\n",
        "plt.xlabel(\"Xeet problem\")\n",
        "plt.ylabel(\"Xeet Length(char)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:18:25.517125Z",
          "iopub.execute_input": "2023-09-06T18:18:25.517688Z",
          "iopub.status.idle": "2023-09-06T18:18:25.746033Z",
          "shell.execute_reply.started": "2023-09-06T18:18:25.517647Z",
          "shell.execute_reply": "2023-09-06T18:18:25.744745Z"
        },
        "trusted": true,
        "id": "dENFjSZPllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing tweet length by words\n",
        "plt.figure(figsize=(10,5))\n",
        "train_sent = train_data['text'].str.split().map(lambda x : len(x))\n",
        "sns.boxplot(x=\"target\",y=train_sent,data=train_data,palette=\"Set1\")\n",
        "plt.xlabel(\"Tweet Fallacy\")\n",
        "plt.ylabel(\"Tweet length by word\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:18:34.192541Z",
          "iopub.execute_input": "2023-09-06T18:18:34.192998Z",
          "iopub.status.idle": "2023-09-06T18:18:34.420890Z",
          "shell.execute_reply.started": "2023-09-06T18:18:34.192961Z",
          "shell.execute_reply": "2023-09-06T18:18:34.419764Z"
        },
        "trusted": true,
        "id": "5fT5FQsdllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['word_count_train'] = train_data['text'].apply(lambda x: len(str(x).split()))\n",
        "test_data['word_count_test'] = test_data['text'].apply(lambda x: len(str(x).split()))\n",
        "train_data['word_count']=train_data['word_count_train']\n",
        "test_data['word_count']=test_data['word_count_test']\n",
        "\n",
        "# unique_word_count\n",
        "train_data['unique_word_count_train'] = train_data['text'].apply(lambda x: len(set(str(x).split())))\n",
        "test_data['unique_word_count_test'] = test_data['text'].apply(lambda x: len(set(str(x).split())))\n",
        "train_data['unique_word_count']=train_data['unique_word_count_train']\n",
        "test_data['unique_word_count']=test_data['unique_word_count_test']\n",
        "# Stopword count\n",
        "train_data['stop_word_count_train'] = train_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "test_data['stop_word_count_test'] = test_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "train_data['stop_word_count']=train_data['stop_word_count_train']\n",
        "test_data['stop_word_count']=test_data['stop_word_count_test']\n",
        "\n",
        "# url_count\n",
        "train_data['url_count'] = train_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "test_data['url_count'] = test_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "\n",
        "# mean_word_length\n",
        "train_data['mean_word_length'] = train_data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test_data['mean_word_length'] = test_data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "\n",
        "# char_count\n",
        "train_data['char_count'] = train_data['text'].apply(lambda x: len(str(x)))\n",
        "test_data['char_count'] = test_data['text'].apply(lambda x: len(str(x)))\n",
        "# Unique word count\n",
        "\n",
        "\n",
        "# URL count\n",
        "train_data['url_count_train'] = train_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "test_data['url_count_test'] = test_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "\n",
        "# Mean word length\n",
        "train_data['mean_word_length_train'] = train_data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test_data['mean_word_length_test'] = test_data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "\n",
        "# Character count\n",
        "train_data['char_count_train'] = train_data['text'].apply(lambda x: len(str(x)))\n",
        "test_data['char_count_test'] = test_data['text'].apply(lambda x: len(str(x)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:18:41.499281Z",
          "iopub.execute_input": "2023-09-06T18:18:41.499733Z",
          "iopub.status.idle": "2023-09-06T18:18:41.776570Z",
          "shell.execute_reply.started": "2023-09-06T18:18:41.499695Z",
          "shell.execute_reply": "2023-09-06T18:18:41.775426Z"
        },
        "trusted": true,
        "id": "T145QtmPllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization:\n",
        "\n",
        "The META list contains the names of the text-related features to be visualized (word_count, unique_word_count, stop_word_count, url_count, mean_word_length, char_count).\n",
        "DISASTER is a boolean array indicating whether each sample in the train_data belongs to a disaster tweet (with a value of 1) or not.\n",
        "Creating Subplots:\n",
        "\n",
        "plt.subplots() creates a grid of subplots with two columns (ncols=2) and a number of rows equal to the length of META. The size of each subplot is adjusted with figsize=(20, 50) and dpi=100.\n",
        "Looping Through Features:\n",
        "\n",
        "A loop iterates over each feature in META.\n",
        "For each feature, two density plots (histograms) are plotted side by side: one for disaster tweets and non-disaster tweets, and the other for the combined training and test sets.\n",
        "In the left subplot (column 0), the distribution of the feature is plotted separately for disaster and non-disaster tweets using seaborn's sns.distplot().\n",
        "In the right subplot (column 1), the distribution of the feature is plotted for the training and test sets combined, again using sns.distplot().\n",
        "Plot Customization:\n",
        "\n",
        "The xlabel, ylabel, and legend for each subplot are adjusted.\n",
        "Titles are set for each subplot, indicating the feature name and whether it's for the training set only or for both training and test sets.\n",
        "Displaying Plots:\n",
        "\n",
        "Finally, plt.show() displays the generated subplots.\n",
        "This visualization helps in understanding the distribution of different text-related features within the training data, comparing these distributions between disaster and non-disaster tweets, and also observing how these features behave across both the training and test datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TluAJ-JvsS8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "META = ['word_count', 'unique_word_count', 'stop_word_count', 'url_count', 'mean_word_length',\n",
        "                'char_count']\n",
        "DISASTER = train_data['target'] == 1\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, nrows=len(META), figsize=(20, 50), dpi=100)\n",
        "\n",
        "for i, feature in enumerate(META):\n",
        "    sns.distplot(train_data.loc[~DISASTER][feature], label='Not Disaster', ax=axes[i][0], color='green')\n",
        "    sns.distplot(train_data.loc[DISASTER][feature], label='Disaster', ax=axes[i][0], color='red')\n",
        "\n",
        "    sns.distplot(train_data[feature], label='Training', ax=axes[i][1])\n",
        "    sns.distplot(test_data[feature], label='Test', ax=axes[i][1])\n",
        "\n",
        "    for j in range(2):\n",
        "        axes[i][j].set_xlabel('')\n",
        "        axes[i][j].tick_params(axis='x', labelsize=12)\n",
        "        axes[i][j].tick_params(axis='y', labelsize=12)\n",
        "        axes[i][j].legend()\n",
        "\n",
        "    axes[i][0].set_title(f'{feature} T Training Set', fontsize=13)\n",
        "    axes[i][1].set_title(f'{feature} Training & Test Set Distribution', fontsize=13)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:18:48.671717Z",
          "iopub.execute_input": "2023-09-06T18:18:48.672171Z",
          "iopub.status.idle": "2023-09-06T18:18:55.515006Z",
          "shell.execute_reply.started": "2023-09-06T18:18:48.672136Z",
          "shell.execute_reply": "2023-09-06T18:18:55.513911Z"
        },
        "trusted": true,
        "id": "6cYxXRXFllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\n",
        "plt.tight_layout()\n",
        "\n",
        "train_data.groupby('target').count()['id'].plot(kind='pie', ax=axes[0], labels=['Not Disaster (57%)', 'Disaster (43%)'])\n",
        "sns.countplot(x=train_data['target'], hue=train_data['target'], ax=axes[1])\n",
        "\n",
        "axes[0].set_ylabel('')\n",
        "axes[1].set_ylabel('')\n",
        "axes[1].set_xticklabels([f'Not Disaster {len(train_data[\"target\"])}', f'Disaster {train_data[\"target\"]}'])\n",
        "axes[0].tick_params(axis='x', labelsize=15)\n",
        "axes[0].tick_params(axis='y', labelsize=15)\n",
        "axes[1].tick_params(axis='x', labelsize=15)\n",
        "axes[1].tick_params(axis='y', labelsize=15)\n",
        "\n",
        "axes[0].set_title('Distrubution Set', fontsize=13)\n",
        "axes[1].set_title(' Training Set', fontsize=13)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:19:13.451348Z",
          "iopub.execute_input": "2023-09-06T18:19:13.451816Z",
          "iopub.status.idle": "2023-09-06T18:19:13.917617Z",
          "shell.execute_reply.started": "2023-09-06T18:19:13.451784Z",
          "shell.execute_reply": "2023-09-06T18:19:13.916313Z"
        },
        "trusted": true,
        "id": "BXqL3qQyllT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT, which stands for Bidirectional Encoder Representations from Transformers, is engineered to pre-train deep bidirectional representations from unlabeled text, considering both left and right context simultaneously. This unique approach enables the pre-trained BERT model to excel across a broad spectrum of NLP tasks with minimal fine-tuning, often requiring just one additional output layer. Notably, BERT's standout feature lies in its capability to extract superior quality language features from textual data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0YpbJFHllT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOADING THE BERT MODEL:\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3sNhlo3llT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bert architecture goes as follows.\n",
        "Input Layer:\n",
        "\n",
        "input_ids_custom and input_mask_custom: These are input layers defined using TensorFlow's Keras API. They are placeholders for sequences of integer tokens (such as word IDs) and attention masks (to indicate which tokens are valid and which are padding), respectively.\n",
        "shape=(max_len,): Specifies the shape of input sequences, where max_len is the maximum length of input sequences.\n",
        "BERT Embeddings:\n",
        "\n",
        "embeddings = bert(input_ids_custom, attention_mask=input_mask_custom)[1]: This line applies the BERT model to the input token IDs (input_ids_custom) and attention masks (input_mask_custom).\n",
        "[1] selects the pooler_output from the BERT model, which provides a representation of the entire input sequence.\n",
        "Dropout Layers:\n",
        "\n",
        "out = tf.keras.layers.Dropout(0.1)(embeddings): Dropout is applied to prevent overfitting by randomly setting a fraction of input units to zero during training. Here, a dropout rate of 0.1 is applied.\n",
        "out = tf.keras.layers.Dropout(0.1)(out): Another dropout layer is added after the first one for further regularization.\n",
        "Dense Layers:\n",
        "\n",
        "out = Dense(128, activation='relu')(out): A dense layer with 128 neurons and ReLU activation function is added to the network. ReLU (Rectified Linear Unit) is a commonly used activation function that introduces non-linearity to the model.\n",
        "out = Dense(32, activation='relu')(out): Another dense layer with 32 neurons and ReLU activation function follows.\n",
        "Output Layer:\n",
        "\n",
        "y = Dense(1, activation='sigmoid')(out): This is the output layer of the model. It consists of a single neuron with a sigmoid activation function, which is commonly used for binary classification tasks. The output represents the probability of the input text belonging to the positive class (e.g., disaster tweet).\n",
        "Model Compilation:\n",
        "\n",
        "model_custom = tf.keras.Model(inputs=[input_ids_custom, input_mask_custom], outputs=y): This line constructs the Keras Model, specifying the input and output layers.\n",
        "model_custom.layers[2].trainable = True: This allows the BERT layer to be fine-tuned during training, enabling the model to adapt to the specific task at hand.\n",
        "Overall, this architecture leverages BERT embeddings to capture contextual information from input text sequences and combines them with dense layers to perform binary classification on text data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1M_XoKyYwx_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\n",
        "bert = TFBertModel.from_pretrained('bert-large-uncased')"
      ],
      "metadata": {
        "trusted": true,
        "id": "8pVJNhY4llT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer('Happy learning and keep kaggling &*&*&&')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:22:59.756554Z",
          "iopub.execute_input": "2023-09-06T18:22:59.757021Z",
          "iopub.status.idle": "2023-09-06T18:22:59.764229Z",
          "shell.execute_reply.started": "2023-09-06T18:22:59.756990Z",
          "shell.execute_reply": "2023-09-06T18:22:59.763128Z"
        },
        "trusted": true,
        "id": "XqSitwCNllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONVERSION OF OUR TEXT DATA INTO BERT INPUT FORMAT:\n",
        "\n"
      ],
      "metadata": {
        "id": "DTCD7Ls-llT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max len of tweets\",max([len(x.split()) for x in train_data.text]))\n",
        "max_length = 36\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:23:20.800737Z",
          "iopub.execute_input": "2023-09-06T18:23:20.801207Z",
          "iopub.status.idle": "2023-09-06T18:23:20.815499Z",
          "shell.execute_reply.started": "2023-09-06T18:23:20.801171Z",
          "shell.execute_reply": "2023-09-06T18:23:20.814388Z"
        },
        "trusted": true,
        "id": "bIjSe5OCllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tokenizer(\n",
        "    text=train_data.text.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=36,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:23:26.852213Z",
          "iopub.execute_input": "2023-09-06T18:23:26.853348Z",
          "iopub.status.idle": "2023-09-06T18:23:27.631555Z",
          "shell.execute_reply.started": "2023-09-06T18:23:26.853306Z",
          "shell.execute_reply": "2023-09-06T18:23:27.630639Z"
        },
        "trusted": true,
        "id": "xLU5w6egllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train['input_ids'].shape\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:23:31.381356Z",
          "iopub.execute_input": "2023-09-06T18:23:31.382159Z",
          "iopub.status.idle": "2023-09-06T18:23:31.389941Z",
          "shell.execute_reply.started": "2023-09-06T18:23:31.382115Z",
          "shell.execute_reply": "2023-09-06T18:23:31.388824Z"
        },
        "trusted": true,
        "id": "-9lYXWS4llT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train['attention_mask'].shape\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:23:37.352029Z",
          "iopub.execute_input": "2023-09-06T18:23:37.352447Z",
          "iopub.status.idle": "2023-09-06T18:23:37.359820Z",
          "shell.execute_reply.started": "2023-09-06T18:23:37.352418Z",
          "shell.execute_reply": "2023-09-06T18:23:37.358491Z"
        },
        "trusted": true,
        "id": "BzHBdU2DllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data.target.values\n",
        "y_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:23:41.735127Z",
          "iopub.execute_input": "2023-09-06T18:23:41.736325Z",
          "iopub.status.idle": "2023-09-06T18:23:41.743538Z",
          "shell.execute_reply.started": "2023-09-06T18:23:41.736273Z",
          "shell.execute_reply": "2023-09-06T18:23:41.742500Z"
        },
        "trusted": true,
        "id": "bU_T8bJwllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.target.value_counts()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:23:47.895873Z",
          "iopub.execute_input": "2023-09-06T18:23:47.896357Z",
          "iopub.status.idle": "2023-09-06T18:23:47.908160Z",
          "shell.execute_reply.started": "2023-09-06T18:23:47.896322Z",
          "shell.execute_reply": "2023-09-06T18:23:47.906981Z"
        },
        "trusted": true,
        "id": "Np_UrP74llT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BUILDING THE MODEL ARCHITECTURE:\n",
        "\n"
      ],
      "metadata": {
        "id": "k3cwNn0GllT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "# embeddings = dbert_model(input_ids,attention_mask = input_mask)[0]\n",
        "\n",
        "\n",
        "embeddings = bert(input_ids,attention_mask = input_mask)[1] #(0 is the last hidden states,1 means pooler_output)\n",
        "# out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = tf.keras.layers.Dropout(0.1)(embeddings)\n",
        "\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "\n",
        "y = Dense(1,activation = 'sigmoid')(out)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:24:13.012187Z",
          "iopub.execute_input": "2023-09-06T18:24:13.012634Z",
          "iopub.status.idle": "2023-09-06T18:24:22.482511Z",
          "shell.execute_reply.started": "2023-09-06T18:24:13.012602Z",
          "shell.execute_reply": "2023-09-06T18:24:22.481271Z"
        },
        "trusted": true,
        "id": "Vh8zOhefllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:24:27.995984Z",
          "iopub.execute_input": "2023-09-06T18:24:27.996420Z",
          "iopub.status.idle": "2023-09-06T18:24:28.074282Z",
          "shell.execute_reply.started": "2023-09-06T18:24:27.996388Z",
          "shell.execute_reply": "2023-09-06T18:24:28.073157Z"
        },
        "trusted": true,
        "id": "fbNGkupZllT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=6e-06, # this learning rate is for bert model.\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = BinaryCrossentropy(from_logits = True)\n",
        "metric = BinaryAccuracy('accuracy'),\n",
        "# Compile the model\n",
        "model_custom.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss,\n",
        "    metrics = metric)"
      ],
      "metadata": {
        "trusted": true,
        "id": "AMwyrtacllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model_custom, show_shapes = True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:25:46.662895Z",
          "iopub.execute_input": "2023-09-06T18:25:46.663311Z",
          "iopub.status.idle": "2023-09-06T18:25:47.035067Z",
          "shell.execute_reply.started": "2023-09-06T18:25:46.663282Z",
          "shell.execute_reply": "2023-09-06T18:25:47.033900Z"
        },
        "trusted": true,
        "id": "J8nZEisZllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "final = model_custom.fit(\n",
        "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
        "    y = y_train,\n",
        "#   validation_split = 0.1,\n",
        "  epochs=9,\n",
        "    batch_size=10\n",
        ")"
      ],
      "metadata": {
        "id": "zNEnqBVallT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/9\n",
        "762/762 [==============================] - 215s 233ms/step - loss: 0.5084 - accuracy: 0.7644\n",
        "Epoch 2/9\n",
        "762/762 [==============================] - 178s 234ms/step - loss: 0.4231 - accuracy: 0.8235\n",
        "Epoch 3/9\n",
        "762/762 [==============================] - 178s 234ms/step - loss: 0.4058 - accuracy: 0.8382\n",
        "Epoch 4/9\n",
        "762/762 [==============================] - 179s 234ms/step - loss: 0.4004 - accuracy: 0.8394\n",
        "Epoch 5/9\n",
        "762/762 [==============================] - 179s 235ms/step - loss: 0.3897 - accuracy: 0.8400\n",
        "Epoch 6/9\n",
        "762/762 [==============================] - 179s 235ms/step - loss: 0.3862 - accuracy: 0.8449\n",
        "Epoch 7/9\n",
        "762/762 [==============================] - 179s 235ms/step - loss: 0.3809 - accuracy: 0.8501\n",
        "Epoch 8/9\n",
        "762/762 [==============================] - 180s 237ms/step - loss: 0.3788 - accuracy: 0.8487\n",
        "Epoch 9/9\n",
        "762/762 [==============================] - 179s 235ms/step - loss: 0.3695 - accuracy: 0.8550"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:27:11.112559Z",
          "iopub.execute_input": "2023-09-06T18:27:11.113004Z",
          "iopub.status.idle": "2023-09-06T18:27:11.122898Z",
          "shell.execute_reply.started": "2023-09-06T18:27:11.112969Z",
          "shell.execute_reply": "2023-09-06T18:27:11.121788Z"
        },
        "id": "y4-PxCigllT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VISUALIZATION OF LOSS AND ACCURACY CURVE:\n",
        "\n"
      ],
      "metadata": {
        "id": "hOC7TniQllT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_accuracy_and_loss(history):\n",
        "    accuracy = history.history['accuracy']\n",
        "    loss = history.history['loss']\n",
        "    epochs = np.arange(1, len(loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, accuracy, 'r', label='Accuracy')\n",
        "    plt.plot(epochs, loss, 'b:', label='Loss')\n",
        "    plt.title('Training Accuracy and Loss Visualization')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:28:27.916860Z",
          "iopub.execute_input": "2023-09-06T18:28:27.917793Z",
          "iopub.status.idle": "2023-09-06T18:28:27.924198Z",
          "shell.execute_reply.started": "2023-09-06T18:28:27.917755Z",
          "shell.execute_reply": "2023-09-06T18:28:27.923098Z"
        },
        "trusted": true,
        "id": "VHMFAfE3llT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_accuracy_and_loss(test_data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:29:07.038179Z",
          "iopub.execute_input": "2023-09-06T18:29:07.038629Z",
          "iopub.status.idle": "2023-09-06T18:29:07.058087Z",
          "shell.execute_reply.started": "2023-09-06T18:29:07.038593Z",
          "shell.execute_reply": "2023-09-06T18:29:07.056755Z"
        },
        "trusted": true,
        "id": "Ch_7cB5UllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = tokenizer(\n",
        "    text=test_data.text.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=36,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:29:15.856803Z",
          "iopub.execute_input": "2023-09-06T18:29:15.857254Z",
          "iopub.status.idle": "2023-09-06T18:29:16.083628Z",
          "shell.execute_reply.started": "2023-09-06T18:29:15.857219Z",
          "shell.execute_reply": "2023-09-06T18:29:16.082674Z"
        },
        "trusted": true,
        "id": "CTvhq8CMllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTION:\n",
        "\n"
      ],
      "metadata": {
        "id": "kbgoUtyUllT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model_custom.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:29:37.082807Z",
          "iopub.execute_input": "2023-09-06T18:29:37.083255Z",
          "iopub.status.idle": "2023-09-06T18:39:52.687484Z",
          "shell.execute_reply.started": "2023-09-06T18:29:37.083223Z",
          "shell.execute_reply": "2023-09-06T18:39:52.686121Z"
        },
        "trusted": true,
        "id": "dozC0OInllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kmv9A0sWtKT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = np.where(predicted>0.5,1,0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:39:52.689878Z",
          "iopub.execute_input": "2023-09-06T18:39:52.690473Z",
          "iopub.status.idle": "2023-09-06T18:39:52.695743Z",
          "shell.execute_reply.started": "2023-09-06T18:39:52.690435Z",
          "shell.execute_reply": "2023-09-06T18:39:52.694634Z"
        },
        "trusted": true,
        "id": "RzC6nzNFllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = y_predicted.reshape((1,3263))[0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:39:52.697147Z",
          "iopub.execute_input": "2023-09-06T18:39:52.698297Z",
          "iopub.status.idle": "2023-09-06T18:39:52.712065Z",
          "shell.execute_reply.started": "2023-09-06T18:39:52.698254Z",
          "shell.execute_reply": "2023-09-06T18:39:52.710911Z"
        },
        "trusted": true,
        "id": "Wi2H_n_OllT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:39:52.714670Z",
          "iopub.execute_input": "2023-09-06T18:39:52.715633Z",
          "iopub.status.idle": "2023-09-06T18:39:52.741910Z",
          "shell.execute_reply.started": "2023-09-06T18:39:52.715594Z",
          "shell.execute_reply": "2023-09-06T18:39:52.740808Z"
        },
        "trusted": true,
        "id": "sr7BEnU9llT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data.to_csv('submission.csv',index = False)\n",
        "print(\" Successfully completed! \")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-06T18:39:52.743243Z",
          "iopub.execute_input": "2023-09-06T18:39:52.743649Z",
          "iopub.status.idle": "2023-09-06T18:39:52.772480Z",
          "shell.execute_reply.started": "2023-09-06T18:39:52.743619Z",
          "shell.execute_reply": "2023-09-06T18:39:52.771286Z"
        },
        "trusted": true,
        "id": "ie-xaX-ellT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0NPQnWBPllT5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}